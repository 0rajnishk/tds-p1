{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0eb9d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Setup\n",
    "token = 'Your Token'\n",
    "headers = {'Authorization': f'token {token}'}\n",
    "users_url = 'https://api.github.com/search/users?q=location:Delhi+followers:>100'\n",
    "\n",
    "# Fetch Users\n",
    "response = requests.get(users_url, headers=headers)\n",
    "users = response.json().get('items', [])\n",
    "\n",
    "# Extract User Data\n",
    "user_data = []\n",
    "for user in users:\n",
    "    login = user['login']\n",
    "    user_info = requests.get(f'https://api.github.com/users/{login}', headers=headers).json()\n",
    "    user_data.append({\n",
    "        'login': user_info.get('login', ''),\n",
    "        'name': user_info.get('name', ''),\n",
    "        'company': (user_info.get('company') or '').lstrip('@').strip().upper(),\n",
    "        'location': user_info.get('location', ''),\n",
    "        'email': user_info.get('email', ''),\n",
    "        'hireable': str(user_info.get('hireable', '')).lower(),\n",
    "        'bio': user_info.get('bio', ''),\n",
    "        'public_repos': user_info.get('public_repos', 0),\n",
    "        'followers': user_info.get('followers', 0),\n",
    "        'following': user_info.get('following', 0),\n",
    "        'created_at': user_info.get('created_at', '')\n",
    "    })\n",
    "\n",
    "# Save Users to CSV\n",
    "users_df = pd.DataFrame(user_data)\n",
    "users_df.to_csv(tpath + 'users.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd99e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16f95b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_data = []\n",
    "\n",
    "for user in users:\n",
    "    login = user['login']\n",
    "    repos_url = f'https://api.github.com/users/{login}/repos?per_page=500'\n",
    "    repos_response = requests.get(repos_url, headers=headers).json()\n",
    "\n",
    "    for repo in repos_response:\n",
    "        repo_data.append({\n",
    "            'login': login,\n",
    "            'full_name': repo.get('full_name', ''),\n",
    "            'created_at': repo.get('created_at', ''),\n",
    "            'stargazers_count': repo.get('stargazers_count', 0),\n",
    "            'watchers_count': repo.get('watchers_count', 0),\n",
    "            'language': repo.get('language', ''),\n",
    "            'has_projects': str(repo.get('has_projects', '')).lower(),\n",
    "            'has_wiki': str(repo.get('has_wiki', '')).lower(),\n",
    "            'license_name': (repo.get('license') or {}).get('key', '')\n",
    "        })\n",
    "\n",
    "# Save Repositories to CSV\n",
    "repos_df = pd.DataFrame(repo_data)\n",
    "repos_df.to_csv(tpath+'repositories.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ded71fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amitshekhariitbhu,shradha-khapra,loveBabbar,Nakshatra05,Anuj-Kumar-Sharma\n",
      "nathvarun,aviaryan,rishikksh20,manrajgrover,the-dagger\n",
      "mit,apache-2.0,other\n",
      "CODEDAMN\n",
      "JavaScript\n",
      "Jupyter Notebook\n",
      "-0.441\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "users_df = pd.read_csv(tpath+'users.csv')\n",
    "repos_df = pd.read_csv(tpath+'repositories.csv')\n",
    "\n",
    "# Q1: Top 5 users by followers\n",
    "top_users = users_df.sort_values(by='followers', ascending=False).head(5)['login'].tolist()\n",
    "print(','.join(top_users))\n",
    "\n",
    "# Q2: Earliest registered users\n",
    "earliest_users = users_df.sort_values(by='created_at').head(5)['login'].tolist()\n",
    "print(','.join(earliest_users))\n",
    "\n",
    "# Q3: Top 3 licenses\n",
    "top_licenses = repos_df['license_name'].value_counts().head(3).index.tolist()\n",
    "print(','.join(top_licenses))\n",
    "\n",
    "# Q4: Most common company\n",
    "most_common_company = users_df['company'].mode().values[0]\n",
    "print(most_common_company)\n",
    "\n",
    "# Q5: Most popular language\n",
    "most_popular_language = repos_df['language'].mode().values[0]\n",
    "print(most_popular_language)\n",
    "\n",
    "# Q6: Second most popular language for post-2020 users\n",
    "users_2020 = users_df[pd.to_datetime(users_df['created_at']) > '2020-01-01']\n",
    "second_popular_language = repos_df[repos_df['login'].isin(users_2020['login'])]['language'].value_counts().index[1]\n",
    "print(second_popular_language)\n",
    "\n",
    "# Q9: Correlation between followers and public repos\n",
    "correlation = users_df['followers'].corr(users_df['public_repos'])\n",
    "print(f'{correlation:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a41f1ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go\n"
     ]
    }
   ],
   "source": [
    "# Group repositories by language and calculate the average stars\n",
    "avg_stars_per_language = repos_df.groupby('language')['stargazers_count'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Get the language with the highest average stars\n",
    "highest_avg_stars_language = avg_stars_per_language.index[0]\n",
    "print(highest_avg_stars_language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45ee4e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anuj-Kumar-Sharma,Ignitetechnologies,shradha-khapra,loveBabbar,amitshekhariitbhu\n"
     ]
    }
   ],
   "source": [
    "# Calculate leader strength as followers / (1 + following)\n",
    "users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
    "\n",
    "# Get top 5 users by leader strength\n",
    "top_leaders = users_df.sort_values(by='leader_strength', ascending=False).head(5)['login'].tolist()\n",
    "print(','.join(top_leaders))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86ba8d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for regression\n",
    "X = users_df[['public_repos']]\n",
    "y = users_df['followers']\n",
    "\n",
    "# Perform linear regression\n",
    "reg = LinearRegression().fit(X, y)\n",
    "slope = reg.coef_[0]\n",
    "\n",
    "print(f'{slope:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e375d6",
   "metadata": {},
   "source": [
    "## Question 11: Correlation Between Projects and Wiki Enabled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d8ef9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "Has Projects Enabled: 0\n",
      "Has Wiki Enabled: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajnish/.local/lib/python3.10/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    }
   ],
   "source": [
    "# Replace missing or invalid values with 0 (assuming no project/wiki in such cases)\n",
    "repos_df['has_projects'] = repos_df['has_projects'].map({'true': 1, 'false': 0}).fillna(0).astype(int)\n",
    "repos_df['has_wiki'] = repos_df['has_wiki'].map({'true': 1, 'false': 0}).fillna(0).astype(int)\n",
    "\n",
    "\n",
    "# Check if there are enough non-zero entries to compute correlation\n",
    "if repos_df[['has_projects', 'has_wiki']].dropna().shape[0] > 1:\n",
    "    correlation_projects_wiki = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
    "    print(f'{correlation_projects_wiki:.3f}')\n",
    "else:\n",
    "    print(\"Not enough data to compute correlation. Check if your dataset is correct.\")\n",
    "\n",
    "    \n",
    "print(\"Has Projects Enabled:\", repos_df['has_projects'].sum())\n",
    "print(\"Has Wiki Enabled:\", repos_df['has_wiki'].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f91e72",
   "metadata": {},
   "source": [
    "# Question 12: Difference in Average Following for Hireable vs. Non-Hireable Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34d70017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1826.187\n"
     ]
    }
   ],
   "source": [
    "# Calculate average following for hireable and non-hireable users\n",
    "hireable_avg_following = users_df[users_df['hireable'] == 'true']['following'].mean()\n",
    "non_hireable_avg_following = users_df[users_df['hireable'] != 'true']['following'].mean()\n",
    "\n",
    "# Calculate the difference\n",
    "difference = hireable_avg_following - non_hireable_avg_following\n",
    "\n",
    "print(f'{difference:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91adc573",
   "metadata": {},
   "source": [
    "# Question 13: Regression Slope of Followers on Bio Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f3e11a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.816\n"
     ]
    }
   ],
   "source": [
    "# Calculate word count of bio (ignore missing bios)\n",
    "users_df['bio_word_count'] = users_df['bio'].fillna('').apply(lambda x: len(x.split()))\n",
    "\n",
    "# Prepare data for regression\n",
    "X = users_df[['bio_word_count']]\n",
    "y = users_df['followers']\n",
    "\n",
    "# Perform linear regression\n",
    "reg = LinearRegression().fit(X, y)\n",
    "slope = reg.coef_[0]\n",
    "\n",
    "print(f'{slope:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05bf2a",
   "metadata": {},
   "source": [
    "## Question 14: Top 5 Users with Most Repos Created on Weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cad1939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AkshayAnand2002,manrajgrover,mehulmpt,ShreyaPrasad1209,saumya1singh\n"
     ]
    }
   ],
   "source": [
    "# Convert 'created_at' to datetime\n",
    "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
    "\n",
    "# Filter for weekend repositories (Saturday=5, Sunday=6)\n",
    "weekend_repos = repos_df[repos_df['created_at'].dt.weekday >= 5]\n",
    "\n",
    "# Count repositories per user and get top 5\n",
    "top_weekend_users = weekend_repos['login'].value_counts().head(5).index.tolist()\n",
    "print(','.join(top_weekend_users))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3b255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e007de1d",
   "metadata": {},
   "source": [
    "# 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5d6bebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.201\n"
     ]
    }
   ],
   "source": [
    "# Calculate fraction of users with email for hireable and non-hireable users\n",
    "hireable_with_email = users_df[users_df['hireable'] == 'true']['email'].notna().mean()\n",
    "non_hireable_with_email = users_df[users_df['hireable'] != 'true']['email'].notna().mean()\n",
    "\n",
    "# Calculate the difference\n",
    "email_fraction_difference = hireable_with_email - non_hireable_with_email\n",
    "\n",
    "print(f'{email_fraction_difference:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8440b9d7",
   "metadata": {},
   "source": [
    "## 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a48de52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singh\n"
     ]
    }
   ],
   "source": [
    "# Extract surname (last word in name) and clean up missing names\n",
    "users_df['surname'] = users_df['name'].fillna('').apply(lambda x: x.strip().split()[-1] if x.strip() else '')\n",
    "\n",
    "# Find the most common surname(s)\n",
    "most_common_surname = users_df['surname'].value_counts()\n",
    "top_surnames = most_common_surname[most_common_surname == most_common_surname.max()].index.tolist()\n",
    "\n",
    "# Print surnames in alphabetical order\n",
    "print(','.join(sorted(top_surnames)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f32289d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
